##
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##

# This file contains some of the configurations for the Kafka Connect distributed worker. This file is intended
# to be used with the examples, and some settings may differ from those used in a production system, especially
# the `bootstrap.servers` and those specifying replication factors.

# A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092

# unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs
group.id=connect-cluster

# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
# need to configure these based on the format they want their data in when loaded from or stored into Kafka
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
# Converter-specific settings can be passed in by prefixing the Converter's setting with the converter we want to apply
# it to
key.converter.schemas.enable=true
value.converter.schemas.enable=true

# Topic to use for storing offsets. This topic should have many partitions and be replicated and compacted.
# Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
# the topic before starting Kafka Connect if a specific topic configuration is needed.
# Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
# Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
# to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
offset.storage.topic=connect-offsets
offset.storage.replication.factor=3
#offset.storage.partitions=25

# Topic to use for storing connector and task configurations; note that this should be a single partition, highly replicated,
# and compacted topic. Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
# the topic before starting Kafka Connect if a specific topic configuration is needed.
# Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
# Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
# to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
config.storage.topic=connect-configs
config.storage.replication.factor=3

# Topic to use for storing statuses. This topic can have multiple partitions and should be replicated and compacted.
# Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
# the topic before starting Kafka Connect if a specific topic configuration is needed.
# Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
# Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
# to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
status.storage.topic=connect-status
status.storage.replication.factor=3
#status.storage.partitions=5

# Flush much faster than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000

# These are provided to inform the user about the presence of the REST host and port configs 
# Hostname & Port for the REST API to listen on. If this is set, it will bind to the interface used to listen to requests.
rest.host.name=connect
rest.port=8083

# The Hostname & Port that will be given out to other workers to connect to i.e. URLs that are routable from other servers.
rest.advertised.host.name=connect
rest.advertised.port=8083

# Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins
# (connectors, converters, transformations). The list should consist of top level directories that include 
# any combination of: 
# a) directories immediately containing jars with plugins and their dependencies
# b) uber-jars with plugins and their dependencies
# c) directories immediately containing the package directory structure of classes of plugins and their dependencies
# Examples: 
# plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors,
# plugin.path=/opt/connectors/debezium-postgres,/opt/connectors/lenses-s3,/opt/connectors/mdrogalis-voluble
plugin.path=/opt/connectors





# SSL
ssl.endpoint.identification.algorithm=https
security.protocol=SASL_SSL
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
request.timeout.ms=20000
retry.backoff.ms=500


# Producer
producer.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
producer.ssl.endpoint.identification.algorithm=https
producer.security.protocol=SASL_SSL
producer.sasl.mechanism=PLAIN
producer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
producer.request.timeout.ms=20000
producer.retry.backoff.ms=500

# Consumer
consumer.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
consumer.ssl.endpoint.identification.algorithm=https
consumer.security.protocol=SASL_SSL
consumer.sasl.mechanism=PLAIN
consumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
consumer.request.timeout.ms=20000
consumer.retry.backoff.ms=500

# Schema Registry specific settings
key.converter.basic.auth.credentials.source=USER_INFO
key.converter.schema.registry.basic.auth.user.info=M6UKQKXOJPO74JGX:UOyGo2Cw7x9j/qn+ZXJS2pg5vlxOjNShk42XdyK90O/VSs62IXjrG6vXchxcl2Oh
key.converter.schema.registry.url=https://psrc-7q7vj.ap-southeast-2.aws.confluent.cloud
value.converter.basic.auth.credentials.source=USER_INFO
value.converter.schema.registry.basic.auth.user.info=M6UKQKXOJPO74JGX:UOyGo2Cw7x9j/qn+ZXJS2pg5vlxOjNShk42XdyK90O/VSs62IXjrG6vXchxcl2Oh
value.converter.schema.registry.url=https://psrc-7q7vj.ap-southeast-2.aws.confluent.cloud

# History
database.history.kafka.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
database.history.producer.security.protocol=SASL_SSL
database.history.producer.ssl.endpoint.identification.algorithm=https
database.history.producer.sasl.mechanism=PLAIN
database.history.producer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
database.history.consumer.security.protocol=SASL_SSL
database.history.consumer.ssl.endpoint.identification.algorithm=https
database.history.consumer.sasl.mechanism=PLAIN
database.history.consumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";


confluent.topic.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
confluent.topic.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
confluent.topic.security.protocol=SASL_SSL
confluent.topic.sasl.mechanism=PLAIN

reporter.admin.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
reporter.admin.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
reporter.admin.security.protocol=SASL_SSL
reporter.admin.sasl.mechanism=PLAIN

reporter.producer.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
reporter.producer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
reporter.producer.security.protocol=SASL_SSL
reporter.producer.sasl.mechanism=PLAIN


confluent.monitoring.interceptor.topic=_confluent-monitoring

consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
consumer.confluent.monitoring.interceptor.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
consumer.confluent.monitoring.interceptor.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
consumer.confluent.monitoring.interceptor.security.protocol=SASL_SSL
consumer.confluent.monitoring.interceptor.sasl.mechanism=PLAIN

producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
producer.confluent.monitoring.interceptor.bootstrap.servers=pkc-e82om.ap-northeast-2.aws.confluent.cloud:9092
producer.confluent.monitoring.interceptor.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"FJHBE7FZJBPS4ZM5\" password=\"uvdwjIxBL1ABlZFYvAocENNPjMksYbqQmjrnN3I2aO0d+xJiu1xsMX4d31F3jcU8\";
producer.confluent.monitoring.interceptor.security.protocol=SASL_SSL
producer.confluent.monitoring.interceptor.sasl.mechanism=PLAIN
