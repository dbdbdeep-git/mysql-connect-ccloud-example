---
version: '3.5'
services:
  mysql-src:
    image: bitnami/mysql:8.0
    container_name: mysql-src
    hostname: mysql-src
    ports:
      - '3306:3306'
    volumes:
      - ./mysql.cnf:/etc/mysql/conf.d/custom.cnf
      - ./initdb.d:/docker-entrypoint-initdb.d
#     - :/docker-entrypoint-startdb.d/
    env_file:
      - common.env
    environment:
      MYSQL_DATABASE: 'mydb'
      MYSQL_ROOT_USER: 'root'
      MYSQL_ROOT_PASSWORD: 'root'
      MYSQL_USER: my_user
      MYSQL_PASSWORD: my_password
      MYSQL_AUTHENTICATION_PLUGIN: mysql_native_password
      MYSQL_CHARACTER_SET: utf8
      MYSQL_COLLATE: utf8_general_ci
#      BITNAMI_DEBUG: 'true'
    healthcheck:
      test: ['CMD', '/opt/bitnami/scripts/mysql/healthcheck.sh']
      interval: 15s
      timeout: 5s
      retries: 10


  mysql-sink:
    image: bitnami/mysql:8.0
    container_name: mysql-sink
    hostname: mysql-sink
    ports:
      - '3307:3307'
    volumes:
      - ./mysql.cnf:/etc/mysql/conf.d/custom.cnf
      - ./initdb.d:/docker-entrypoint-initdb.d
#     - :/docker-entrypoint-startdb.d/
    env_file:
      - common.env
    environment:
      MYSQL_DATABASE: 'mydb'
      MYSQL_ROOT_USER: 'root'
      MYSQL_ROOT_PASSWORD: 'root'
      MYSQL_USER: my_user
      MYSQL_PASSWORD: my_password
      MYSQL_AUTHENTICATION_PLUGIN: mysql_native_password
      MYSQL_CHARACTER_SET: utf8
      MYSQL_COLLATE: utf8_general_ci
    healthcheck:
      test: ['CMD', '/opt/bitnami/scripts/mysql/healthcheck.sh']
      interval: 15s
      timeout: 5s
      retries: 10


  connect:
    image: confluentinc/cp-kafka-connect:7.1.1
    container_name: connect
    hostname: connect
    ports:
      - "5005:5005"
      - "8083:8083"
      - "10002:10002"
    env_file:
      - common.env
    volumes:
#      - "./connectors/connect-distributed.properties:/opt/bitnami/kafka/config/connect-distributed.properties"
      - "./connectors/debezium-connector-mysql-2.0.0.Alpha1:/usr/share/confluent-hub-components/debezium-mysql"
      - "./connectors/confluentinc-kafka-connect-jdbc-10.4.1:/usr/share/confluent-hub-components/kafka-connnect-jdbc"
      - "./connectors/confluentinc-kafka-connect-avro-converter-7.1.1:/usr/share/confluent-hub-components/confluentinc-avro-converter"
#      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    environment:
      KAFKA_JMX_PORT: 10002
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_BOOTSTRAP_SERVERS: $BOOTSTRAP_SERVERS
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: $SCHEMA_REGISTRY_URL
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components # only load one connector to speed up deployment (it is overidden in connect tests)
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: $BOOTSTRAP_SERVERS
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: $BOOTSTRAP_SERVERS
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=âœ¨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=ðŸ”¬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  -XX:MaxInlineLevel=15 -Djava.awt.headless=true
    
      # Configure the Connect workers to use SASL/PLAIN.
      CONNECT_SASL_MECHANISM: PLAIN
      CONNECT_SECURITY_PROTOCOL: SASL_PLAINTEXT 
    
      # JAAS
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"connect\" \
                password=\"connect-secret\";"
    
      # producer
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"connect\" \
                password=\"connect-secret\";"
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM: PLAIN 
    
      # consumer
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"connect\" \
                password=\"connect-secret\";"
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM: PLAIN

      # producer
      CONNECT_PRODUCER_SASL_MECHANISM: PLAIN
      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"connect\" \
                password=\"connect-secret\";"
      # consumer
      CONNECT_CONSUMER_SASL_MECHANISM: PLAIN
      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"connect\" \
                password=\"connect-secret\";"


  ksqldb-server:
    image: ${CP_KSQL_IMAGE}:${TAG}
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker
      - connect
    ports:
      - "8088:8088"
      - "10003:10003"
    profiles:
    - ksqldb
    environment:
      KSQL_JMX_PORT: 10003
      KSQL_JMX_HOSTNAME: localhost
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: broker:9092
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      # KSQL_KSQL_STREAMS_PROCESSING_GUARANTEE=exactly_once
      # --- ksqlDB Server log config ---
      KSQL_LOG4J_ROOT_LOGLEVEL: "INFO"
      KSQL_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      # --- ksqlDB processing log config ---
      # KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: broker:9092
      # KSQL_LOG4J_PROCESSING_LOG_TOPIC: ksql_processing_log
      # KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: ksql_processing_log
      # KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      # KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      # KSQL_KSQL_LOGGING_PROCESSING_ROWS_INCLUDE: 'true'
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      # KSQL_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # KSQL_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KSQL_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KSQL_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'


  ksqldb-server:
        environment:
            KSQL_SECURITY_PROTOCOL: SASL_PLAINTEXT
            KSQL_SASL_MECHANISM: PLAIN
            KSQL_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"ksqldb\" \
                password=\"ksqldb-secret\";"
            # producer
            KSQL_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL: SASL_PLAINTEXT
            KSQL_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"ksqldb\" \
                password=\"ksqldb-secret\";"
            KSQL_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM: PLAIN
            # consumer
            KSQL_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL: SASL_PLAINTEXT
            KSQL_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"ksqldb\" \
                password=\"ksqldb-secret\";"
            KSQL_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM: PLAIN


  ksqldb-cli:
    image: ${CP_KSQL_CLI_IMAGE}
    container_name: ksqldb-cli
    depends_on:
      - broker
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    profiles:
    - ksqldb
    tty: true


 control-center:
    image: confluentinc/cp-enterprise-control-center:${TAG}
    hostname: control-center
    container_name: control-center
    restart: always
    depends_on:
      - broker
      - schema-registry
      - connect
    ports:
      - "9021:9021"
    profiles:
    - control-center
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_CLUSTER: http://connect:8083 # deprecated
      CONTROL_CENTER_CONNECT_MYCONNECT_CLUSTER: http://connect:8083
      CONTROL_CENTER_KAFKA_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_KAFKA_MYCLUSTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_UI_AUTOUPDATE_ENABLE: "false"
      CONTROL_CENTER_KSQL_URL: "http://ksqldb-server:8088" # deprecated
      CONTROL_CENTER_KSQL_ADVERTISED_URL: "http://127.0.0.1:8088" # deprecated
      CONTROL_CENTER_KSQL_MYKSQL_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_MYKSQL_ADVERTISED_URL: "http://127.0.0.1:8088"
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
      CONTROL_CENTER_METRICS_TOPIC_REPLICATION: 1
      # METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      # starting from 7.0
      #CONTROL_CENTER_MODE_ENABLE: management
      # CONTROL_CENTER_ID: 32





  control-center:
    environment:
      CONTROL_CENTER_STREAMS_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONTROL_CENTER_STREAMS_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
         username=\"client\" \
         password=\"client-secret\";"
      CONTROL_CENTER_STREAMS_SASL_MECHANISM: PLAIN
      CONTROL_CENTER_KAFKA_MYCLUSTER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONTROL_CENTER_KAFKA_MYCLUSTER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required \
                username=\"client\" \
                password=\"client-secret\";"
      CONTROL_CENTER_KAFKA_MYCLUSTER_SASL_MECHANISM: PLAIN
                                                                         









  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    hostname: kafka-ui
    ports:
      - "8080:8080"
    env_file:
      - common.env
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:22181
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://registry:8080/apis/ccompat/v6
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: local
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://connect:8083
    depends_on:
      - connect



  kafka-lag-exporter:
    image: lightbend/kafka-lag-exporter:0.6.6
    hostname: kafka-lag-exporter
    container_name: kafka-lag-exporter
    profiles:
      - "grafana"
    restart: always
    ports:
      - 9998:9998
    volumes:
      - ./kafka-lag-exporter/application.conf:/opt/docker/conf/application.conf
      - ./kafka-lag-exporter/logback.xml:/opt/docker/conf/logback.xml

  alertmanager:
    image: prom/alertmanager:v0.18.0
    hostname: alertmanager
    container_name: alertmanager
    profiles:
      - "grafana"
    ports:
      - 9093:9093

  node-exporter:
    image: prom/node-exporter:v0.18.1
    hostname: node-exporter
    container_name: node-exporter
    profiles:
      - "grafana"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.ignored-mount-points'
      - '^(aufs|proc|nsfs|shm|cgroup|tmpfs|binfmt_misc|debugfs|devpts|fusectl|hugetlbfs|fuse.lxcfs|mqueue|pstore|securityfs|sysfs|autofs|devtmpfs|configfs)'

  prometheus:
    image: prom/prometheus
    hostname: prometheus
    container_name: prometheus
    profiles:
      - "grafana"
    ports:
      - 9090:9090
    volumes:
      - ./prometheus/:/etc/prometheus/
    depends_on:
      - node-exporter
      - kafka-lag-exporter
      - alertmanager

  grafana:
    image: grafana/grafana:7.4.1
    hostname: grafana
    container_name: grafana
    profiles:
      - "grafana"
    environment:
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    ports:
      - 3000:3000
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/config/grafana.ini:/etc/grafana/grafana.ini
    depends_on:
      - prometheus
                                                                     


